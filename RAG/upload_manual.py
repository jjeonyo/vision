import os
import time
import google.generativeai as genai
from supabase import create_client, Client
from pypdf import PdfReader

# ==========================================
# 1. ì„¤ì • ì •ë³´ (ì—¬ê¸°ë¥¼ ê¼­ ì±„ì›Œì£¼ì„¸ìš”!)
# ==========================================
SUPABASE_URL = "https://wzafalbctqkylhyzlfej.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Ind6YWZhbGJjdHFreWxoeXpsZmVqIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2NDAzNTM5NywiZXhwIjoyMDc5NjExMzk3fQ.Ax6HgxBruVRbUIhYtmDKK1yW8OkoSGjFg3GLupS91uI" # service_role í‚¤ ê¶Œì¥
GOOGLE_API_KEY = "AIzaSyCE8-7jyJBbugZX6GRCMvGhPfBtkZeXXY0"

# íŒŒì¼ëª…ê³¼ ëª¨ë¸ëª… í™•ì¸
PDF_FILE_PATH = "MFL69354434_190730_Koream.pdf" 
TARGET_DOC_TITLE = "F24 ì‹œë¦¬ì¦ˆ ìƒì„¸ ë§¤ë‰´ì–¼"
TARGET_MODEL_ID = "F24WD" 
# ==========================================

genai.configure(api_key=GOOGLE_API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def get_embedding(text):
    """Gemini ì„ë² ë”© ìš”ì²­ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)"""
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document"
        )
        return result['embedding']
    except Exception as e:
        print(f"  âš ï¸ ì„ë² ë”© ì¤‘ ì—ëŸ¬: {e}")
        return None

def split_text_into_chunks(text, chunk_size=600, overlap=100):
    """
    í…ìŠ¤íŠ¸ë¥¼ ì •í•´ì§„ í¬ê¸°ë¡œ ìë¦…ë‹ˆë‹¤.
    ë¬¸ë§¥ì´ ëŠê¸°ì§€ ì•Šê²Œ overlap(100ì)ë§Œí¼ ê²¹ì³ì„œ ìë¦…ë‹ˆë‹¤.
    """
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        # ë‹¤ìŒ ì¡°ê°ì€ overlapë§Œí¼ ë’¤ë¡œ ê°€ì„œ ì‹œì‘ (ê²¹ì¹˜ê¸°)
        start += (chunk_size - overlap)
    return chunks

def upload_manual_to_supabase():
    print(f"ğŸ“‚ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {PDF_FILE_PATH}")
    
    # 1. íŒŒì¼ ì½ê¸°
    try:
        reader = PdfReader(PDF_FILE_PATH)
    except FileNotFoundError:
        print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ë¬¸ì„œ ì •ë³´ ë“±ë¡ (ê¸°ì¡´ ì½”ë“œëŠ” ìœ ì§€í•˜ë˜, ì¤‘ë³µ ë°©ì§€ ë¡œì§ì€ ìƒëµí•¨)
    print("ğŸ“ ë¬¸ì„œ ì •ë³´ ë“±ë¡ ì¤‘...")
    doc_data = {
        "title": TARGET_DOC_TITLE,
        "version": "v1.0",
        "file_url": "local_upload"
    }
    doc_res = supabase.table("manual_documents").insert(doc_data).execute()
    doc_id = doc_res.data[0]['doc_id']
    
    # ëª¨ë¸ ì—°ê²°
    link_data = {"model_id": TARGET_MODEL_ID, "doc_id": doc_id}
    supabase.table("manual_model_links").insert(link_data).execute()
    print(f"âœ… ë¬¸ì„œ ID ë°œê¸‰ ì™„ë£Œ: {doc_id}")

    # 3. [í•µì‹¬] í˜ì´ì§€ë³„ Chunking ë° ì €ì¥
    print("âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„í•  ë° ì €ì¥ ì‹œì‘ (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)...")
    
    total_chunks = 0
    
    for i, page in enumerate(reader.pages):
        raw_text = page.extract_text()
        if not raw_text or len(raw_text) < 50:
            continue # ë¹ˆ í˜ì´ì§€ ê±´ë„ˆëœ€
            
        # ê³µë°± ì •ë¦¬
        clean_text = raw_text.replace('\n', ' ').replace('  ', ' ').strip()
        
        # ğŸŒŸ ì—¬ê¸°ì„œ í…ìŠ¤íŠ¸ë¥¼ ì˜ê²Œ ìª¼ê°­ë‹ˆë‹¤ (Chunking)
        chunks = split_text_into_chunks(clean_text, chunk_size=600, overlap=100)
        
        print(f"  ğŸ“– {i+1}í˜ì´ì§€ -> {len(chunks)}ê°œ ì¡°ê°ìœ¼ë¡œ ë¶„í• ë¨")

        for idx, chunk_text in enumerate(chunks):
            # ë¬´ë£Œ API ì œí•œ ë°©ì§€ (2ì´ˆ ëŒ€ê¸°)
            time.sleep(2)
            
            vector = get_embedding(chunk_text)
            
            if vector:
                section_data = {
                    "doc_id": doc_id,
                    "category": "manual_content",
                    "section_title": f"{i+1}í˜ì´ì§€-{idx+1}", # ì¶œì²˜ í‘œì‹œ
                    "content_text": chunk_text,
                    "page_number": i + 1,
                    "embedding_vector": vector
                }
                
                # í•˜ë‚˜ì”© ë°”ë¡œë°”ë¡œ ì €ì¥ (ì—ëŸ¬ë‚˜ë©´ ì–´ë””ì„œ ë‚¬ëŠ”ì§€ ì•Œê¸° ìœ„í•´)
                try:
                    supabase.table("manual_sections").insert(section_data).execute()
                    total_chunks += 1
                    print(f"    -> ì¡°ê° {idx+1} ì €ì¥ ì™„ë£Œ ({len(chunk_text)}ì)")
                except Exception as e:
                    print(f"    âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

    print(f"\nğŸ‰ ì‘ì—… ë! ì´ {total_chunks}ê°œì˜ ì§€ì‹ ì¡°ê°ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    upload_manual_to_supabase()