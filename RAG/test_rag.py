import os
import google.generativeai as genai
from dotenv import load_dotenv
from supabase import create_client, Client

# ==========================================
# 1. ì„¤ì • ì •ë³´ upload_manual.pyì™€ ë™ì¼í•˜ê²Œ ì…ë ¥)
# ==========================================
load_dotenv()  # load variables from .env into environment

SUPABASE_URL = "https://wzafalbctqkylhyzlfej.supabase.co"
SUPABASE_KEY = os.getenv("supbase_service_role")
GOOGLE_API_KEY = os.getenv("google_api")
# ==========================================

# API ì´ˆê¸°í™”
genai.configure(api_key=GOOGLE_API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ë‹µë³€ì„ ìƒì„±í•  Gemini ëª¨ë¸ ì„¤ì • (ë¹ ë¥´ê³  ë˜‘ë˜‘í•œ 2.5 Flash ì¶”ì²œ)
generation_model = genai.GenerativeModel('gemini-2.5-flash')

def get_embedding(text):
    """ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜"""
    result = genai.embed_content(
        model="models/text-embedding-004",
        content=text,
        task_type="retrieval_query" # ë¬¸ì„œë¥¼ ì°¾ê¸° ìœ„í•œ ì§ˆë¬¸ìš© íƒ€ì…
    )
    return result['embedding']

def search_manual(query_text):
    """DBì—ì„œ ìœ ì‚¬í•œ ë§¤ë‰´ì–¼ ë‚´ìš© ê²€ìƒ‰ (RAG - Retrieval)"""
    
    # âœ… [1] ì—¬ê¸°ê°€ ë¹ ì ¸ì„œ ì—ëŸ¬ê°€ ë‚¬ë˜ ê²ë‹ˆë‹¤! (ì§ˆë¬¸ -> ë²¡í„° ë³€í™˜)
    query_vector = get_embedding(query_text)
    
    # ì„ë² ë”©ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš° ë°©ì–´ ì½”ë“œ
    if not query_vector:
        print("âŒ ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return []

    # [2] Supabase ê²€ìƒ‰ ìš”ì²­
    # (ì£¼ì˜: ë§Œì•½ model_id í•„í„°ë§ ê¸°ëŠ¥ì„ ì•„ì§ RPC í•¨ìˆ˜ì— ì•ˆ ë„£ìœ¼ì…¨ë‹¤ë©´ filter_model_id ì¤„ì€ ì§€ìš°ì„¸ìš”)
    response = supabase.rpc("match_manual_sections", {
        "query_embedding": query_vector,
        "match_threshold": 0.1, # ì ìˆ˜ë¥¼ 0.3ìœ¼ë¡œ ë‚®ì¶¤ (ë” ë§ì´ ì°¾ê²Œ)
        "match_count": 5
    }).execute()
    
    # [3] ë””ë²„ê¹…: ë¬´ì—‡ì´ ê²€ìƒ‰ëëŠ”ì§€ ëˆˆìœ¼ë¡œ í™•ì¸
    if response.data:
        print(f"\nğŸ” '{query_text}' ê²€ìƒ‰ ê²°ê³¼ (Top 5):")
        for i, item in enumerate(response.data):
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ 100ìë§Œ ë³´ì—¬ì£¼ê¸°
            preview = item['content_text'][:100].replace('\n', ' ')
            print(f"   [{i+1}] ìœ ì‚¬ë„: {item['similarity']:.4f} | ì œëª©: {item['section_title']}")
            print(f"       ë‚´ìš©: {preview}...")
            print("-" * 40)
    else:
        print("\nâš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„ ê¸°ì¤€ ë¯¸ë‹¬)")
    
    return response.data

def generate_answer(query_text, context_list):
    """ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„± (RAG - Generation)"""
    
    if not context_list:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë§¤ë‰´ì–¼ì—ì„œ ê´€ë ¨ëœ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
    context_text = "\n\n".join([f"- {item['content_text']}" for item in context_list])

    # Geminiì—ê²Œ ì¤„ í”„ë¡¬í”„íŠ¸ (í˜ë¥´ì†Œë‚˜ ë¶€ì—¬)
    prompt = f"""
    ë‹¹ì‹ ì€ LG ìŠ¤íƒ ë“œ ì—ì–´ì»¨ ì‚¬ìš©ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ [ë§¤ë‰´ì–¼ ë‚´ìš©]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ [ì§ˆë¬¸]ì— ë‹µë³€í•˜ì„¸ìš”.
    ë©”ë‰´ì–¼ì— ì œê³µë˜ì§€ ì•Šì€ ë‚´ìš©ì€ ë©”ë‰´ì–¼ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ê³  ë‹µë³€í•´
    ì§ˆë¬¸ì„ ë¬¸ì œìƒí™©ì— ë§ê²Œ ì›ì¸ê³¼ í•´ê²°ë°©ë²•ì„ í•¨ê»˜ ë‹µë³€í•´ì£¼ì„¸ìš”.
    
    [ë§¤ë‰´ì–¼ ë‚´ìš©]:
    {context_text}
    
    [ì§ˆë¬¸]:
    {query_text}
    
    [ë‹µë³€]:
    """
    
    # AI ë‹µë³€ ìƒì„±
    response = generation_model.generate_content(prompt)
    return response.text

def main():
    print("ğŸ¤– ì—ì–´ì»¨ AI ì±—ë´‡ í…ŒìŠ¤íŠ¸ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")
    print("-" * 50)
    
    while True:
        user_input = input("\nì§ˆë¬¸í•˜ì„¸ìš”: ")
        if user_input.lower() == 'exit':
            break
            
        print("ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰ ì¤‘...")
        
        # 1. DB ê²€ìƒ‰
        search_results = search_manual(user_input)
        
        if search_results:
            print(f"   => ì°¸ê³ í•œ ë§¤ë‰´ì–¼ ì„¹ì…˜: {[item['section_title'] for item in search_results]}")
        else:
            print("   => âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (ìœ ì‚¬ë„ ë‚®ìŒ)")
            
        # 2. ë‹µë³€ ìƒì„±
        answer = generate_answer(user_input, search_results)
        
        print("\nğŸ’¬ AI ë‹µë³€:")
        print(answer)
        print("-" * 50)

if __name__ == "__main__":
    main()