import asyncio
import os
import cv2
import pathlib
import sys
import time
import pyaudio
import warnings
import traceback
import threading
import queue
import speech_recognition as sr
import audioop
import sqlite3
import textwrap
import firebase_admin
from firebase_admin import credentials
from firebase_admin import db
from dotenv import load_dotenv

# [ìˆ˜ì •] google.genaiì—ì„œ types ìž„í¬íŠ¸
try:
    from google import genai
    from google.genai import types
except ImportError:
    print("âŒ google-genai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# [ì„¤ì •] ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore")

# ==========================================
# [ì„¤ì •] í™˜ê²½ ë³€ìˆ˜
# ==========================================

def load_environment():
    try:
        current_dir = pathlib.Path(__file__).parent.absolute()
        env_path = None
        for parent in [current_dir] + list(current_dir.parents):
            check_path = parent / ".env"
            if check_path.exists():
                env_path = check_path
                break

        if env_path:
            load_dotenv(dotenv_path=env_path)
        else:
            print("âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ .env ë¡œë“œ ì˜¤ë¥˜: {e}")

load_environment()

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("âŒ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)


MODEL_ID = "gemini-2.5-flash-native-audio-preview-09-2025"
#MODEL_ID = "gemini-2.5-flash"
#MODEL_ID = "gemini-2.5-flash-preview-09-2025"
#MODEL_ID = "gemini-2.0-flash"
#MODEL_ID = "gemini-2.0-flash-exp"

# [ì˜¤ë””ì˜¤ ì„¤ì •]
AUDIO_FORMAT = pyaudio.paInt16
CHANNELS = 1
INPUT_RATE = 16000
OUTPUT_RATE = 24000
CHUNK_SIZE = 512
MIC_DEVICE_INDEX = None

# ==========================================
# [í•¨ìˆ˜] ì„¤ì • ë° íŽ˜ë¥´ì†Œë‚˜ ë¡œë“œ
# ==========================================

def get_config():
    current_dir = pathlib.Path(__file__).parent.absolute()
    persona_path = current_dir / "persona_ì„¸íƒë²•.txt"
    
    system_instruction = ""
    if persona_path.exists():
        try:
            system_instruction = persona_path.read_text(encoding="utf-8")
            print(f"ðŸŽ­ íŽ˜ë¥´ì†Œë‚˜ ë¡œë“œë¨: {persona_path.name}")
        except Exception:
            pass
    else:
        system_instruction = "ë„ˆëŠ” ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‹¤ì‹œê°„ìœ¼ë¡œ ëŒ€í™”í•´."

    return {
        "response_modalities": ["AUDIO"],
        "speech_config": {
            "voice_config": {
                "prebuilt_voice_config": {
                    "voice_name": "Aoede"
                }
            }
        },
        "system_instruction": system_instruction
    }

# ==========================================
# [í´ëž˜ìŠ¤] DB ë¡œê·¸ ì €ìž¥ (Firebase Realtime Database)
# ==========================================
class DatabaseLogger:
    def __init__(self, cred_path="firebase_key.json", database_url="https://YOUR_PROJECT_ID-default-rtdb.firebaseio.com/"):
        self.cred_path = cred_path
        self.database_url = database_url
        self.buffer = []
        self.session_id = None
        self._init_firebase()
        self._start_session()

    def _init_firebase(self):
        """Firebase ì´ˆê¸°í™”"""
        try:
            # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if not firebase_admin._apps:
                cred = credentials.Certificate(self.cred_path)
                firebase_admin.initialize_app(cred, {
                    'databaseURL': self.database_url
                })
                print("ðŸ”¥ Firebase ì—°ê²° ì„±ê³µ!")
            else:
                print("ðŸ”¥ Firebase ì´ë¯¸ ì—°ê²°ë¨")
        except Exception as e:
            print(f"âŒ Firebase ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            print("âš ï¸ firebase_key.json íŒŒì¼ê³¼ database_urlì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    def _start_session(self):
        """ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ì‹œìž‘"""
        try:
            # ì„¸ì…˜ ID ìƒì„± (íƒ€ìž„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
            self.session_id = str(int(time.time()))
            session_ref = db.reference(f'sessions/{self.session_id}')
            
            session_data = {
                'start_time': time.strftime("%Y-%m-%d %H:%M:%S"),
                'model_id': MODEL_ID
            }
            session_ref.set(session_data)
            print(f"ðŸ’¾ Firebase ì„¸ì…˜ ì‹œìž‘ë¨: ID {self.session_id}")
        except Exception as e:
            print(f"âŒ ì„¸ì…˜ ì‹œìž‘ ì˜¤ë¥˜: {e}")

    def append_text(self, text):
        self.buffer.append(text)

    def log_user_message(self, text):
        """ì‚¬ìš©ìž ë©”ì‹œì§€ ì €ìž¥"""
        try:
            if self.session_id:
                messages_ref = db.reference(f'sessions/{self.session_id}/messages')
                new_message_ref = messages_ref.push() # ê³ ìœ  í‚¤ ìƒì„±
                
                message_data = {
                    'sender': 'user',
                    'content': text,
                    'created_at': time.strftime("%Y-%m-%d %H:%M:%S")
                }
                new_message_ref.set(message_data)
        except Exception as e:
            print(f"\nâš ï¸ Firebase ì €ìž¥ ì‹¤íŒ¨ (User): {e}")

    def flush_model_turn(self):
        """ëª¨ë¸ ì‘ë‹µ ì €ìž¥"""
        if not self.buffer: return
        
        full_text = "".join(self.buffer)
        
        try:
            if self.session_id:
                messages_ref = db.reference(f'sessions/{self.session_id}/messages')
                new_message_ref = messages_ref.push()
                
                message_data = {
                    'sender': 'gemini',
                    'content': full_text,
                    'created_at': time.strftime("%Y-%m-%d %H:%M:%S")
                }
                new_message_ref.set(message_data)
        except Exception as e:
            print(f"\nâš ï¸ Firebase ì €ìž¥ ì‹¤íŒ¨ (Gemini): {e}")
            
        self.buffer = []
    
    def save_feedback(self, score):
        """í”¼ë“œë°± ì €ìž¥"""
        try:
            if self.session_id:
                session_ref = db.reference(f'sessions/{self.session_id}')
                session_ref.update({
                    'feedback': score
                })
                print("âœ… Firebaseì— í”¼ë“œë°± ì €ìž¥ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ í”¼ë“œë°± ì €ìž¥ ì˜¤ë¥˜: {e}")

# ==========================================
# [í´ëž˜ìŠ¤] STT ì²˜ë¦¬ê¸° (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)
# ==========================================
class SpeechTranscriber:
    def __init__(self, logger, shared_state=None):
        self.logger = logger
        self.shared_state = shared_state
        self.audio_queue = queue.Queue()
        self.running = True
        self.recognizer = sr.Recognizer()
        
        # STT ì„¤ì •
        self.energy_threshold = 1000  # ìŒì„± ê°ì§€ ìž„ê³„ê°’ (ì¡°ì ˆ í•„ìš”)
        self.pause_threshold = 0.8    # ë§ ëŠê¹€ ê°„ì£¼ ì‹œê°„ (ì´ˆ)
        self.sample_rate = 16000
        self.sample_width = 2         # 16-bit = 2 bytes

        self.thread = threading.Thread(target=self._process_loop, daemon=True)
        self.thread.start()
    
    def add_audio(self, data):
        if self.running:
            self.audio_queue.put(data)
            
    def stop(self):
        self.running = False
        self.thread.join(timeout=1.0)

    def _process_loop(self):
        print("ðŸ‘‚ STT ë¦¬ìŠ¤ë„ˆ ì‹œìž‘ (í•œêµ­ì–´)")
        
        audio_buffer = bytearray()
        silence_frames = 0
        has_voice = False
        
        # 1 í”„ë ˆìž„(ì²­í¬) ë‹¹ ì‹œê°„ ê³„ì‚°
        # CHUNK_SIZE(512) / RATE(16000) = 0.032ì´ˆ
        chunk_duration = 512 / 16000
        pause_frame_count = int(self.pause_threshold / chunk_duration)
        
        while self.running:
            try:
                # íì—ì„œ ì˜¤ë””ì˜¤ ì²­í¬ ê°€ì ¸ì˜¤ê¸° (íƒ€ìž„ì•„ì›ƒ 1ì´ˆ)
                data = self.audio_queue.get(timeout=1.0)
                
                # ì—ë„ˆì§€(ì†Œë¦¬ í¬ê¸°) ê³„ì‚°
                rms = audioop.rms(data, self.sample_width)
                
                if rms > self.energy_threshold:
                    has_voice = True
                    silence_frames = 0
                else:
                    if has_voice:
                        silence_frames += 1
                
                # ë²„í¼ì— ë°ì´í„° ì¶”ê°€
                if has_voice:
                    audio_buffer.extend(data)
                
                # ë§ì´ ëë‚¬ë‹¤ê³  íŒë‹¨ë˜ë©´ (ì¼ì • ì‹œê°„ ì¹¨ë¬µ)
                if has_voice and silence_frames > pause_frame_count:
                    # ì¸ì‹ ìˆ˜í–‰
                    self._recognize(audio_buffer)
                    
                    # ì´ˆê¸°í™”
                    audio_buffer = bytearray()
                    silence_frames = 0
                    has_voice = False
                    
                # ë²„í¼ê°€ ë„ˆë¬´ ì»¤ì§€ë©´ (ì˜ˆ: 15ì´ˆ ì´ìƒ) ê°•ì œ ì¸ì‹ (ë©”ëª¨ë¦¬ ë³´í˜¸)
                if len(audio_buffer) > 16000 * 2 * 15:
                    self._recognize(audio_buffer)
                    audio_buffer = bytearray()
                    silence_frames = 0
                    has_voice = False

            except queue.Empty:
                continue
            except Exception as e:
                print(f"STT ë£¨í”„ ì˜¤ë¥˜: {e}")
                
    def _recognize(self, audio_data):
        if len(audio_data) < 16000 * 2 * 0.5: # 0.5ì´ˆ ë¯¸ë§Œì€ ë¬´ì‹œ
            return
            
        try:
            # Raw PCM ë°ì´í„°ë¥¼ AudioData ê°ì²´ë¡œ ë³€í™˜
            audio_source = sr.AudioData(bytes(audio_data), self.sample_rate, self.sample_width)
            
            # Google Web Speech API í˜¸ì¶œ (ë™ê¸°)
            text = self.recognizer.recognize_google(audio_source, language="ko-KR")
            if text.strip():
                print(f"\n[ðŸ—£ï¸ User]: {text}")
                self.logger.log_user_message(text)
                
                # shared_state ì ‘ê·¼ì´ ì–´ë ¤ìš°ë¯€ë¡œ ë¡œê±°ë¥¼ í†µí•´ ìš°íšŒí•˜ê±°ë‚˜ ì „ì—­ ë³€ìˆ˜ ê³ ë ¤
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨ížˆ ì „ì—­ shared_stateê°€ ì—†ìœ¼ë¯€ë¡œ ìƒëžµí•˜ê±°ë‚˜ 
                # SpeechTranscriberì— shared_state ì°¸ì¡°ë¥¼ ë„˜ê²¨ì£¼ëŠ” ê²ƒì´ ì¢‹ìŒ
                if hasattr(self, 'shared_state') and self.shared_state:
                     self.shared_state["display_text"] = "..."
                
        except sr.UnknownValueError:
            # ì¸ì‹ ì‹¤íŒ¨ (ìž¡ìŒ ë“±) - ì¡°ìš©ížˆ ë„˜ì–´ê°
            pass
        except sr.RequestError as e:
            print(f"STT API ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ==========================================
# [ë©”ì¸] ì‹¤í–‰ ë£¨í”„
# ==========================================

async def main():
    try:
        client = genai.Client(api_key=API_KEY)
        config = get_config()
        p = pyaudio.PyAudio()
        
        input_stream = None
        output_stream = None

        try:
            output_stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=OUTPUT_RATE, output=True)
            input_stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=INPUT_RATE, input=True, 
                                  input_device_index=MIC_DEVICE_INDEX, frames_per_buffer=CHUNK_SIZE)
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            return

        cap = cv2.VideoCapture(0)
        # ë‚´ í™”ë©´ìš© í•´ìƒë„ (ê³ í•´ìƒë„)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\nðŸš€ ëª¨ë¸({MODEL_ID}) ì—°ê²° ì¤‘...")


        # ê³µìœ  ë°ì´í„° ì»¨í…Œì´ë„ˆ (ë¯¸ë¦¬ ì •ì˜í•˜ì—¬ STTì— ì „ë‹¬)
        shared_state = {
            "latest_frame": None, 
            "running": True,
            "display_text": "ì•ˆë…•í•˜ì„¸ìš”!" 
        }

        logger = DatabaseLogger()
        stt_transcriber = SpeechTranscriber(logger, shared_state)

        try:
            async with client.aio.live.connect(model=MODEL_ID, config=config) as session:
                print("âœ… ì—°ê²° ì„±ê³µ! ëŒ€í™”ë¥¼ ì‹œìž‘í•˜ì„¸ìš”. (ì¢…ë£Œ: Ctrl+C ë˜ëŠ” í™”ë©´ì—ì„œ 'q')")
                
                # -------------------------------------------------------
                # [Task 1] ë¹„ë””ì˜¤ ì²˜ë¦¬ (í™”ë©´ í‘œì‹œ + ì „ì†¡ ë¶„ë¦¬)
                # -------------------------------------------------------
                
                async def capture_and_display():
                    print("ðŸ“· ì¹´ë©”ë¼ ìº¡ì²˜ ì‹œìž‘")
                    while shared_state["running"]:
                        ret, frame = cap.read()
                        if not ret: 
                            print("âŒ ì¹´ë©”ë¼ í”„ë ˆìž„ ì½ê¸° ì‹¤íŒ¨")
                            break

                        shared_state["latest_frame"] = frame.copy()

                        cv2.imshow('Gemini Live Vision', frame)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            shared_state["running"] = False
                            break
                        
                        # í™”ë©´ ê°±ì‹  (ì•½ 30 FPS)
                        await asyncio.sleep(0.03)
                async def send_video_frames():
                    print("ðŸ“¡ ë¹„ë””ì˜¤ ì „ì†¡ ë°ëª¬ ì‹œìž‘")
                    while shared_state["running"]:
                        if shared_state["latest_frame"] is not None:
                            frame = shared_state["latest_frame"]
                            
                            # ì „ì†¡ ê·œê²© 640x480
                            frame_resized = cv2.resize(frame, (640, 480))
                            _, buffer = cv2.imencode('.jpg', frame_resized, [int(cv2.IMWRITE_JPEG_QUALITY), 50])
                            
                            try:
                                await session.send_realtime_input(
                                    video=types.Blob(
                                        data=buffer.tobytes(), 
                                        mime_type="image/jpeg"
                                    )
                                )
                            except TypeError:
                                await session.send_realtime_input(
                                    data=buffer.tobytes(), 
                                    mime_type="image/jpeg"
                                )
                            except Exception as e:
                                print(f"ë¹„ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                        
                        # ì „ì†¡ ì£¼ê¸° (0.4ì´ˆ = 2.5 FPS)
                        await asyncio.sleep(0.4)
                
                # -------------------------------------------------------
                # [Task 2] ì˜¤ë””ì˜¤ ìž…ë ¥
                # -------------------------------------------------------
                async def send_audio_stream():
                    print("ðŸŽ™ï¸ ë§ˆì´í¬ ì „ì†¡ ì‹œìž‘")
                    while True:
                        try:
                            data = await asyncio.to_thread(input_stream.read, CHUNK_SIZE, exception_on_overflow=False)
                            
                            # STT ì²˜ë¦¬ë¥¼ ìœ„í•´ ë°ì´í„° ë³µì‚¬ë³¸ ì „ë‹¬
                            stt_transcriber.add_audio(data)
                            
                            # [ìˆ˜ì •] ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ audio=types.Blob(...) í˜•íƒœë¡œ ì „ì†¡
                            await session.send_realtime_input(
                                audio=types.Blob(
                                    data=data, 
                                    mime_type="audio/pcm;rate=16000"
                                )
                            )
                        except Exception as e:
                            print(f"ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: {e}")
                            break

                # -------------------------------------------------------
                # [Task 3] ì‘ë‹µ ìˆ˜ì‹ 
                # -------------------------------------------------------
                async def receive_response():
                    while True:
                        try:
                            async for response in session.receive():
                                if response.server_content:
                                    model_turn = response.server_content.model_turn
                                    if model_turn:
                                        for part in model_turn.parts:
                                            if part.inline_data:
                                                output_stream.write(part.inline_data.data)
                                            if part.text:
                                                print(part.text, end="", flush=True)
                                                logger.append_text(part.text)

                                    # í„´ì´ ëë‚¬ëŠ”ì§€ í™•ì¸ (API ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìžˆìŒ)
                                    # turn_completeê°€ ëª…ì‹œì ìœ¼ë¡œ ì˜¤ë©´ ì €ìž¥
                                    if getattr(response.server_content, "turn_complete", False):
                                        logger.flush_model_turn()
                                        
                        except Exception as e:
                            print(f"ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
                            break

                video_display_task = asyncio.create_task(capture_and_display())
                video_sender_task = asyncio.create_task(send_video_frames())
                audio_task = asyncio.create_task(send_audio_stream())
                recv_task = asyncio.create_task(receive_response())

                try:
                    # ì¹´ë©”ë¼ ì°½ì´ ë‹«íž ë•Œê¹Œì§€ ëŒ€ê¸°
                    await video_display_task
                except asyncio.CancelledError:
                    pass
                finally:
                    video_sender_task.cancel()
                    audio_task.cancel()
                    recv_task.cancel()

        except Exception as e:
            print(f"\nâŒ ì„¸ì…˜ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
        finally:
            stt_transcriber.stop()
            
            # [ì¢…ë£Œ ì‹œí€€ìŠ¤] ì‚¬ìš©ìž í”¼ë“œë°± ìˆ˜ì§‘
            print("\n" + "="*40)
            print("ðŸ‘‹ ìƒë‹´ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            try:
                feedback = input("ðŸ’¡ ì´ë²ˆ ìƒë‹´ì´ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? (y/n): ").strip().lower()
                feedback_score = 1 if feedback == 'y' else 0
                
                # ë§ˆì§€ë§‰ ì„¸ì…˜ ID ê°€ì ¸ì˜¤ê¸° ë° í”¼ë“œë°± ì—…ë°ì´íŠ¸
                if logger.session_id:
                    logger.save_feedback(feedback_score)
            except Exception as e:
                print(f"í”¼ë“œë°± ì €ìž¥ ì˜¤ë¥˜: {e}")
            print("="*40 + "\n")

            if cap.isOpened(): cap.release()
            if input_stream: input_stream.stop_stream(); input_stream.close()
            if output_stream: output_stream.stop_stream(); output_stream.close()
            if p: p.terminate()
            cv2.destroyAllWindows()

    except Exception as e:
        print(f"\nâŒ ë©”ì¸ ì˜¤ë¥˜: {e}")
        input("ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤...")

if __name__ == "__main__":
    asyncio.run(main())