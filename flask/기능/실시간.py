import asyncio
import os
import cv2
import pathlib
import sys
import pyaudio
from dotenv import load_dotenv
from google import genai

# ==========================================
# [ì„¤ì •] í™˜ê²½ ë³€ìˆ˜ ë° ì˜¤ë””ì˜¤ ì„¤ì •
# ==========================================

# .env íŒŒì¼ ìë™ íƒìƒ‰
current_dir = pathlib.Path(__file__).parent.absolute()
env_path = None
for parent in [current_dir] + list(current_dir.parents):
    check_path = parent / ".env"
    if check_path.exists():
        env_path = check_path
        break

if env_path:
    load_dotenv(dotenv_path=env_path)
else:
    print("âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("âŒ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

MODEL_ID = "gemini-2.0-flash-exp"

# ì˜¤ë””ì˜¤ ì„¤ì • (Gemini Live í‘œì¤€)
# ì…ë ¥(ë§ˆì´í¬): 16kHz, 1ì±„ë„, 16bit
# ì¶œë ¥(ìŠ¤í”¼ì»¤): 24kHz, 1ì±„ë„, 16bit
AUDIO_FORMAT = pyaudio.paInt16
CHANNELS = 1
INPUT_RATE = 16000
OUTPUT_RATE = 24000
CHUNK_SIZE = 512

# ==========================================
# [í•¨ìˆ˜] ìœ í‹¸ë¦¬í‹°
# ==========================================

def load_system_instruction():
    file_path = current_dir / "persona.txt"
    if not file_path.exists():
        file_path = current_dir.parent.parent / "persona.txt"
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except:
        return "ë‹¹ì‹ ì€ LGì „ì AI ì„¸íƒ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í™”ë©´ì„ ë³´ê³  ì¹œì ˆí•˜ê²Œ ë§ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."

# ==========================================
# [ë©”ì¸] ë¹„ë™ê¸° ì‹¤í–‰ ë£¨í”„
# ==========================================

async def main():
    client = genai.Client(api_key=API_KEY)
    
    # PyAudio ì´ˆê¸°í™”
    p = pyaudio.PyAudio()

    # 1. ìŠ¤í”¼ì»¤ ìŠ¤íŠ¸ë¦¼ (AI ëª©ì†Œë¦¬ ì¶œë ¥)
    try:
        output_stream = p.open(format=AUDIO_FORMAT,
                               channels=CHANNELS,
                               rate=OUTPUT_RATE,
                               output=True)
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì¶œë ¥ ì¥ì¹˜ ì˜¤ë¥˜: {e}")
        return

    # 2. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ (ì‚¬ìš©ì ëª©ì†Œë¦¬ ì…ë ¥)
    try:
        input_stream = p.open(format=AUDIO_FORMAT,
                              channels=CHANNELS,
                              rate=INPUT_RATE,
                              input=True,
                              frames_per_buffer=CHUNK_SIZE)
    except Exception as e:
        print(f"âŒ ë§ˆì´í¬ ì…ë ¥ ì¥ì¹˜ ì˜¤ë¥˜: {e}")
        return

    # 3. ì›¹ìº  ì„¤ì •
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    if not cap.isOpened():
        print("âŒ ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nğŸš€ ëª¨ë¸({MODEL_ID}) ì—°ê²° ì¤‘... (ìŒì„± ëŒ€í™” ëª¨ë“œ)")
    print("ğŸ¤ ê¶ê¸ˆí•œ ì ì„ 'ë§ì”€'í•´ ì£¼ì„¸ìš”.")
    print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ ì˜ìƒ ì°½ì„ í´ë¦­í•˜ê³  'q'ë¥¼ ëˆ„ë¥´ì„¸ìš”.")

    # [í•µì‹¬] ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ë°›ë„ë¡ ì„¤ì •
    config = {"response_modalities": ["AUDIO", "TEXT"]}

    try:
        async with client.aio.live.connect(model=MODEL_ID, config=config) as session:
            # í˜ë¥´ì†Œë‚˜ ì£¼ì…
            await session.send(input=load_system_instruction(), end_of_turn=True)
            print("âœ… ì—°ê²° ì™„ë£Œ! ë“£ê³  ìˆìŠµë‹ˆë‹¤...")

            # -------------------------------------------------------
            # [Task 1] ë¹„ë””ì˜¤ ì „ì†¡ (OpenCV -> Gemini)
            # -------------------------------------------------------
            async def send_video_stream():
                while True:
                    ret, frame = cap.read()
                    if not ret: break

                    cv2.imshow('AI Washing Tutor (Voice Mode)', frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break

                    frame_resized = cv2.resize(frame, (640, 480))
                    _, buffer = cv2.imencode('.jpg', frame_resized, [int(cv2.IMWRITE_JPEG_QUALITY), 50])
                    
                    try:
                        await session.send(input={"data": buffer.tobytes(), "mime_type": "image/jpeg"}, end_of_turn=False)
                    except:
                        break
                    
                    await asyncio.sleep(0.4) # í”„ë ˆì„ ì „ì†¡ ì£¼ê¸° ì¡°ì ˆ

                cap.release()
                cv2.destroyAllWindows()

            # -------------------------------------------------------
            # [Task 2] ì˜¤ë””ì˜¤ ì…ë ¥ ì „ì†¡ (Mic -> Gemini)
            # -------------------------------------------------------
            async def send_audio_stream():
                while True:
                    # ë§ˆì´í¬ì—ì„œ ë°ì´í„° ì½ê¸° (Blocking ë°©ì§€ë¥¼ ìœ„í•´ to_thread ì‚¬ìš©)
                    try:
                        data = await asyncio.to_thread(input_stream.read, CHUNK_SIZE, exception_on_overflow=False)
                        await session.send(input={"data": data, "mime_type": "audio/pcm"}, end_of_turn=False)
                    except:
                        break

            # -------------------------------------------------------
            # [Task 3] ì‘ë‹µ ìˆ˜ì‹  (Gemini -> Speaker & Console)
            # -------------------------------------------------------
            async def receive_response():
                while True:
                    try:
                        async for response in session.receive():
                            server_content = response.server_content
                            if server_content is not None:
                                model_turn = server_content.model_turn
                                if model_turn is not None:
                                    for part in model_turn.parts:
                                        # í…ìŠ¤íŠ¸ ì¶œë ¥
                                        if part.text:
                                            print(f"\rğŸ¤– AI: {part.text}", end="")
                                        
                                        # ì˜¤ë””ì˜¤ ì¶œë ¥
                                        if part.inline_data:
                                            output_stream.write(part.inline_data.data)
                                    
                                    # í„´ì´ ëë‚¬ì„ ë•Œ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (ì„ íƒ ì‚¬í•­)
                                    if response.server_content.turn_complete:
                                        print("\n")
                                        
                    except Exception as e:
                        print(f"ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
                        break

            # íƒœìŠ¤í¬ ê·¸ë£¹ ì‹¤í–‰
            # send_video_streamì´ ë©”ì¸ ì»¨íŠ¸ë¡¤ëŸ¬ ì—­í•  (q ëˆ„ë¥´ë©´ ì¢…ë£Œ)
            video_task = asyncio.create_task(send_video_stream())
            audio_task = asyncio.create_task(send_audio_stream())
            recv_task = asyncio.create_task(receive_response())

            await video_task

            # ì¢…ë£Œ ì²˜ë¦¬
            audio_task.cancel()
            recv_task.cancel()
            
            # ìŠ¤íŠ¸ë¦¼ ë‹«ê¸°
            input_stream.stop_stream()
            input_stream.close()
            output_stream.stop_stream()
            output_stream.close()
            p.terminate()

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ìì› ì •ë¦¬
        if cap.isOpened(): cap.release()
        p.terminate()

if __name__ == "__main__":
    if sys.platform.startswith('win'):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())