import asyncio
import os
import cv2
import pathlib
import sys
import pyaudio
from dotenv import load_dotenv
from google import genai

# ==========================================
# [ì„¤ì •] í™˜ê²½ ë³€ìˆ˜ ë° ì˜¤ë””ì˜¤ ì„¤ì •
# ==========================================

current_dir = pathlib.Path(__file__).parent.absolute()
env_path = None
for parent in [current_dir] + list(current_dir.parents):
    check_path = parent / ".env"
    if check_path.exists():
        env_path = check_path
        break

if env_path:
    load_dotenv(dotenv_path=env_path)

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("âŒ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

MODEL_ID = os.getenv("MODEL_NAME")

# ì˜¤ë””ì˜¤ ì„¤ì • (Gemini Live í‘œì¤€: 16kHz ì…ë ¥ / 24kHz ì¶œë ¥)
AUDIO_FORMAT = pyaudio.paInt16
CHANNELS = 1
INPUT_RATE = 16000
OUTPUT_RATE = 24000
CHUNK_SIZE = 512
MIC_DEVICE_INDEX = None
# ==========================================
# [í•¨ìˆ˜] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì˜ìƒ ì¸ì‹ ê°•í™”)
# ==========================================

def load_system_instruction():
    system_prompt = """
    [Role]
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì›¹ìº ì„ í†µí•´ ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ë³´ê³ , ì‚¬ìš©ìì˜ ëª©ì†Œë¦¬ë¥¼ ë“£ëŠ” AI íŒŒíŠ¸ë„ˆì…ë‹ˆë‹¤.
    
    [Mandatory Rules]
    1. ì‚¬ìš©ìê°€ ë§ì„ ê±¸ë©´, ë°˜ë“œì‹œ 'í˜„ì¬ í™”ë©´ì— ë³´ì´ëŠ” ì‹œê°ì  ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    2. "í™”ë©´ì´ ì•ˆ ë³´ì¸ë‹¤", "í…ìŠ¤íŠ¸ ëª¨ë¸ì´ë‹¤" ë“±ì˜ ë§ì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì§€ê¸ˆ í™”ë©´ì„ ë³´ê³  ìˆìŠµë‹ˆë‹¤.
    3. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¡œ ì§§ê²Œ ë§í•˜ì„¸ìš”.
    4. í™”ë©´ì— ë³€í™”ê°€ ìˆê±°ë‚˜ íŠ¹ì´í•œ ë¬¼ê±´ì´ ë³´ì´ë©´ ë¨¼ì € ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.
    """
    return system_prompt

# ==========================================
# [ë©”ì¸] ë¹„ë™ê¸° ì‹¤í–‰ ë£¨í”„
# ==========================================

async def main():
    client = genai.Client(api_key=API_KEY)
    
    # [ì„¤ì •] ì‘ë‹µ ëª¨ë“œë¥¼ AUDIOë¡œ ì„¤ì • (ìŒì„± ë‹µë³€ ìˆ˜ì‹ )
    config = {"response_modalities": ["AUDIO"]}
    
    # PyAudio ì´ˆê¸°í™”
    p = pyaudio.PyAudio()
    
    try:
        # ìŠ¤í”¼ì»¤ ìŠ¤íŠ¸ë¦¼
        output_stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=OUTPUT_RATE, output=True)
        # ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼
        input_stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=INPUT_RATE, input=True, frames_per_buffer=CHUNK_SIZE)
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì¥ì¹˜ ì˜¤ë¥˜: {e}")
        return

    # ì›¹ìº  ì„¤ì •
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    if not cap.isOpened():
        print("âŒ ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nğŸš€ ëª¨ë¸({MODEL_ID}) ì—°ê²° ì¤‘... (ìŒì„± ëŒ€í™” ëª¨ë“œ)")
    print("ğŸ¤ ë§ˆì´í¬ì— ëŒ€ê³  ë§ì”€í•˜ì„¸ìš”. (ì´ì–´í° ê¶Œì¥)")
    print("ğŸ‘ï¸ ì˜ìƒ ë°ì´í„° ì „ì†¡ ì¤‘: .")

    try:
        async with client.aio.live.connect(model=MODEL_ID, config=config) as session:
            # í˜ë¥´ì†Œë‚˜ ì£¼ì…
            await session.send(input=load_system_instruction(), end_of_turn=True)
            print("âœ… ì—°ê²° ì™„ë£Œ! ë“£ê³  ë³´ê³  ìˆìŠµë‹ˆë‹¤.")

            # -------------------------------------------------------
            # [Task 1] ë¹„ë””ì˜¤ ì „ì†¡ (OpenCV -> Gemini)
            # -------------------------------------------------------
            async def send_video_stream():
                while True:
                    ret, frame = cap.read()
                    if not ret: break

                    cv2.imshow('AI Vision (Voice Mode) - press q to quit', frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break

                    frame_resized = cv2.resize(frame, (640, 480))
                    _, buffer = cv2.imencode('.jpg', frame_resized, [int(cv2.IMWRITE_JPEG_QUALITY), 50])
                    
                    try:
                        await session.send(input={"data": buffer.tobytes(), "mime_type": "image/jpeg"}, end_of_turn=False)
                        print(".", end="", flush=True) # ì „ì†¡ í™•ì¸ìš© ì 
                        if user_input.strip().lower() in ['quit', 'q','ã…‚', 'ì¢…ë£Œ']:
                            print("ì¢…ë£Œ ëª…ë ¹ í™•ì¸.")
                            break                            
                    except:
                        break
                    
                    await asyncio.sleep(0.5) # ì „ì†¡ ì£¼ê¸°

                cap.release()
                cv2.destroyAllWindows()

            # -------------------------------------------------------
            # [Task 2] ì˜¤ë””ì˜¤ ì…ë ¥ (Mic -> Gemini)
            # -------------------------------------------------------
            async def send_audio_stream():
                while True:
                    try:
                        # ë§ˆì´í¬ ì…ë ¥ ë¹„ë™ê¸° ì²˜ë¦¬
                        data = await asyncio.to_thread(input_stream.read, CHUNK_SIZE, exception_on_overflow=False)
                        await session.send(input={"data": data, "mime_type": "audio/x-linear16", "sample_rate": INPUT_RATE}, end_of_turn=False)

                    except Exception as e:
                        print(f"Mic Error: {e}")
                        break

            # -------------------------------------------------------
            # [Task 3] ì˜¤ë””ì˜¤ ì‘ë‹µ ìˆ˜ì‹  (Gemini -> Speaker)
            # -------------------------------------------------------
            async def receive_response():
                while True:
                    try:
                        async for response in session.receive():
                            # ì˜¤ë””ì˜¤ ë°ì´í„° ì¬ìƒ
                            if hasattr(response, 'server_content') and response.server_content:
                                model_turn = response.server_content.model_turn
                                if model_turn and hasattr(model_turn, 'parts'):
                                    for part in model_turn.parts:
                                        if hasattr(part, 'inline_data') and part.inline_data:
                                            if part.inline_data.data:
                                                output_stream.write(part.inline_data.data)
                    except Exception as e:
                        print(f"Receive Error: {e}")
                        break

            # íƒœìŠ¤í¬ ì‹¤í–‰
            video_task = asyncio.create_task(send_video_stream())
            audio_input_task = asyncio.create_task(send_audio_stream())
            recv_task = asyncio.create_task(receive_response())

            # ì¢…ë£Œ ëŒ€ê¸° (ë¹„ë””ì˜¤ ì°½ ë‹«í ë•Œê¹Œì§€)
            await video_task

            # ì •ë¦¬
            audio_input_task.cancel()
            recv_task.cancel()

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        # ìì› í•´ì œ
        if cap.isOpened(): cap.release()
        if input_stream: input_stream.stop_stream(); input_stream.close()
        if output_stream: output_stream.stop_stream(); output_stream.close()
        if p: p.terminate()

if __name__ == "__main__":
    if sys.platform.startswith('win'):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())